<!DOCTYPE html>
<html lang="zh">
<head>

        <title>EM算法</title>
        <meta charset="utf-8" />
        <link href="http://www.wengweitao.com/feeds\all.atom.xml" type="application/atom+xml" rel="alternate" title="wwt's blog Full Atom Feed" />
        <link href="http://www.wengweitao.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="wwt's blog Full RSS Feed" />
        <link href="http://www.wengweitao.com/feeds/ji-qi-xue-xi.rss.xml" type="application/atom+xml" rel="alternate" title="wwt's blog Categories Atom Feed" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">
        <meta name="google-site-verification" content="pEViDEEJCicDD__DfnOAQ7xKtjtxJhVDoGDAOahOWy0" />

        <meta name="sogou_site_verification" content="ia8yXdZS0p"/>
 

        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/gumby.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/style.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/pygment.css" />

        <script src="http://www.wengweitao.com/theme/js/libs/modernizr-2.6.2.min.js"></script>




</head>

<body id="index" class="home">


    <div class="container">

        <div class="row">

          <header id="banner" class="body">
                  <h1><a href="http://www.wengweitao.com/">wwt's blog <strong></strong></a></h1>
          </header><!-- /#banner -->

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>
             
              <ul class="columns">
                <li><a href="http://www.wengweitao.com/">首页</a></li>

                <li><a href="/categories.html">分类</a></li>
                <li><a href="/tags.html">标签</a></li>
                <li><a href="/archives.html">归档</a></li>
                <li><a href="/pages/about-me.html">关于我</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">


            <header>
              <h2 class="entry-title">
                <a href="http://www.wengweitao.com/emsuan-fa.html" rel="bookmark"
                   title="Permalink to EM算法">EM算法</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2014-08-10T19:09:00">
                Sun 10 August 2014
              </abbr>
              <address class="vcard author">By 
                <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
              </address>
            </footer><!-- /.post-info -->
            <div class="entry-content">
              <blockquote>
<p>EM算法是一种迭代算法，用于含有隐变量（hidden variable）的概率模型参数的极大似然估计，或极大后验概率估计。EM算法的每次迭代分为两步：E步，求期望（Expectation）；M步，求极大（Maximization）。所以这一算法称为期望极大算法。</p>
</blockquote>
<h2>EM算法的引入</h2>
<p>如果概率模型中仅含有观测变量（observable variable），那么给定数据，可以直接使用极大似然估计法或贝叶斯估计法估计模型参数。但是，如果概率模型中不仅含有观测变量还含有隐变量，那么就不能简单的使用那些估计方法。EM算法就是含有隐变量的概率模型参数的极大似然估计法，或极大后验概率估计法。</p>
<h3>EM算法</h3>
<p>输入：观测变量数据Y，隐变量数据Z，联合分布<span class="math">\(P(Y,Z|\theta)\)</span>，条件分布<span class="math">\(P(Z|Y,\theta)\)</span>;</p>
<p>输出：模型参数<span class="math">\(\theta\)</span></p>
<p>（1）选择参数的初值<span class="math">\(\theta^{(0)}\)</span>，开始迭代；</p>
<p>（2）E步：记<span class="math">\(\theta^{(i)}\)</span>为第i次迭代参数<span class="math">\(\theta\)</span>的估计值，在第i+1次迭代的E步，计算
</p>
<div class="math">$$Q(\theta, \theta^{(i)})=E_Z[logP(Y,Z|\theta)|Y,\theta^{(i)}]=\sum_ZlogP(Y,Z|\theta)P(Z|Y,\theta^{(i)})$$</div>
<p>（3）M步：求使<span class="math">\(Q(\theta, \theta^{(i)})\)</span>极大化的<span class="math">\(\theta\)</span>，确定第i+1次迭代的参数估计值<span class="math">\(\theta^{(i+1)}\)</span>
</p>
<div class="math">$$\theta^{(i+1)}=argmax_\theta Q(\theta, \theta^{(i)})$$</div>
<p>（4）重复第（2）步与第（3）步，直到收敛</p>
<p>其中<span class="math">\(Q(\theta, \theta^{(i)})\)</span>是算法的核心，称为<strong>Q函数</strong>。其中第一个<span class="math">\(\theta\)</span>表示要极大化的参数，第二个变元表示参数的当前估计值，每次迭代实际在求Q函数及其极大（M步中求极大，并完成一次迭代更新，可以证明每次迭代使似然函数增大或者达到局部极值）。</p>
<p>完全数据的对数似然函数<span class="math">\(logP(Y,Z|\theta)\)</span>关于在给定观测数据Y和当前参数<span class="math">\(\theta^{(i)}\)</span>下对未观测数据Z的条件概率分布<span class="math">\(P(Y,Z|\theta^{(i)})\)</span>的期望称为Q函数
</p>
<div class="math">$$Q(\theta, \theta^{(i)})=E_Z[logP(Y,Z|\theta)|Y,\theta^{(i)}]$$</div>
<p>步骤（1）中，初值可以任意选择，但是EM算法对初值是敏感的；</p>
<p>步骤（4）中，迭代的终止条件，一般是对较小的正数<span class="math">\(\varepsilon_1, \varepsilon_2\)</span>，若满足
</p>
<div class="math">$$||\theta^{(i+1)}-\theta^{(i)}||&lt;\varepsilon_1$$</div>
<p>
或
</p>
<div class="math">$$||Q(\theta^{(i+1)}, \theta^{(i)})-Q(\theta^{(i)}, \theta^{(i)})||&lt;\varepsilon_2$$</div>
<p>
则停止迭代。</p>
<p>举一个三硬币模型。假设有3枚硬币，分别记为A,B,C。每次都先抛A硬币，若为正面，则抛B硬币，反面则抛C硬币，此时的结果不能观测到，记此结果为Z；然后抛B或C硬币，若出现正面记为1，反面记为0，此时的结果作为观测变量记为Y。求此模型的参数，即三枚硬币正面分别出现的概率a,b和c。</p>
<p>Y表示观测随机变量的数据，Z表示隐随机变量的数据。Y和Z连在一起称为完全数据（complete data），观测数据Y又称为不完全数据。假设给定观测数据Y，其概率分布是<span class="math">\(P(Y|\theta)\)</span>，其中<span class="math">\(\theta\)</span>就是要求的模型参数。不完全数据Y的似然函数是<span class="math">\(P(Y|\theta)\)</span>，对数似然函数是<span class="math">\(L(\theta)=logP(Y|\theta)\)</span>；Y和Z的联合概率分布是<span class="math">\(P(Y,Z|\theta)\)</span>，那么完全数据的对数似然函数是<span class="math">\(logP(Y，Z|\theta)\)</span>。</p>
<p>EM算法通过迭代求<span class="math">\(L(\theta)=logP(Y|\theta)\)</span>的极大似然估计（**观测数据数据每次迭代包含两步：E步，求期望；M步，求极大化。</p>
<h3>EM算法的导出</h3>
<p>EM算法为什么能近似实现对观测数据的极大似然估计呢？下面通过近似求解观测数据的对数似然函数的极大化问题来导出EM算法。</p>
<p>面对一个含有隐变量的概率模型，目标是极大化观测数据（不完全数据）Y关于参数<span class="math">\(\theta\)</span>的对数似然函数，即极大化
</p>
<div class="math">$$L(\theta)=logP(Y|\theta)=log\sum_ZP(Y,Z)|\theta)=log(\sum_ZP(Y|Z,\theta)P(Z|\theta))$$</div>
<p>
上面的式子含有未观测 并且含有和的对数，所以很难直接极大化。</p>
<p>假设第i次迭代后<span class="math">\(\theta\)</span>的估计值为<span class="math">\(\theta^{(i)}\)</span>，我们希望新的估计值<span class="math">\(\theta\)</span>能使<span class="math">\(L(\theta)\)</span>的值更大，并逐步达到极大值。考虑两者的差：
</p>
<div class="math">$$L(\theta)-L(\theta^{(i)})=log(\sum_ZP(Y|Z,\theta)P(Z|\theta))-logP(Y|\theta^{(i)})$$</div>
<p> 
利用Jensen不等式<sup id="fnref:Jesen"><a class="footnote-ref" href="#fn:Jesen" rel="footnote">1</a></sup>,可以得到其下界：
</p>
<div class="math">$$L(\theta)-L(\theta^{(i)}) \geq \sum_ZP(Z|Y,\theta^{(i)})log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})}$$</div>
<p>
令
</p>
<div class="math">$$B(\theta,\theta^{(1)})=L(\theta^{(i)})+\sum_ZP(Z|Y,\theta^{(i)})log\frac{P(Y|Z,\theta)P(Z|\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})}$$</div>
<p>
则<span class="math">\(B(\theta,\theta^{(1)})\)</span>是<span class="math">\(L(\theta)\)</span>的一个下界，而且<span class="math">\(L(\theta^{(i)})=B(\theta^{(i)},\theta^{(i)})\)</span>。所以，任意可以使<span class="math">\(B(\theta,\theta^{(1)})\)</span>增大的<span class="math">\(\theta\)</span>，也可以使<span class="math">\(L(\theta)\)</span>增大。选择<span class="math">\(\theta^{(i+1)}\)</span>使得
</p>
<div class="math">$$\theta^{(i+1)}=argmax_\theta B(\theta, \theta^{(i+1)})$$</div>
<p>
然后可以得到：
</p>
<div class="math">$$\theta^{(i+1)}=argmax_\theta Q(\theta, \theta^{(i)})$$</div>
<p>
等价于EM算法的一次迭代，即求Q函数及其极大化。EM算法是通过不断求解其下界的极大化逼近求解对数似然函数极大化的算法。</p>
<p>但是，EM算法不能保证找到全局最优值。</p>
<h3>EM算法在非监督学习中的应用</h3>
<p>有时训练数据只有输入而没有输出，从这样的数据学习模型称为非监督学习问题。EM算法可以用于非监督学习，生成模型由联合概率分布P(X,Y)（相当于P(Y)）表示，可以认为非监督学习训练数据是联合概率分布产生的数据。X为观测数据，Y为非观测数据。</p>
<hr />
<h2>EM算法的收敛性</h2>
<p>EM算法提供一种近似计算含有隐含变量概率模型的极大似然估计的方法。EM算法的最大优点是简单性和普适性。EM算法得到的估计序列是否收敛？</p>
<p>设<span class="math">\(P(Y|\theta)\)</span>为观测数据的似然函数，<span class="math">\(\theta^{(i)}(i=1,2,...)\)</span>为EM算法得到的参数估计序列，<span class="math">\(P(Y|\theta^{(i)})(i=1,2,...)\)</span>为对应的似然函数序列，则<span class="math">\(P(Y|\theta^{i})\)</span>是单调递增的，即
</p>
<div class="math">$$P(Y|\theta^{(i+1)}) \geq P(Y|\theta^{(i)})$$</div>
<p>设<span class="math">\(L(\theta)=logP(Y|\theta)\)</span>为观测数据的对数似然函数，<span class="math">\(\theta^{(i)}(i=1,2,...)\)</span>为EM算法得到的参数估计序列，<span class="math">\(L(\theta^{(i)})(i=1,2,...)\)</span>为为对应的对数似然函数序列。</p>
<p>（1）如果<span class="math">\(P(Y|\theta)\)</span>有上界，则<span class="math">\(L(\theta^{(i)})=logP(Y|\theta^{(i)})\)</span>收敛到某一直<span class="math">\(L^*\)</span></p>
<p>（2）<span class="math">\(Q(\theta, \theta')与L(\theta)\)</span>满足一定条件下，由EM算法得到的参数估计序列<span class="math">\(\theta^{(i)}\)</span>的收敛值<span class="math">\(\theta^{*}\)</span>是<span class="math">\(L(\theta)\)</span>的稳定点。</p>
<p>稳定点，不能保证收敛到极大值点。所以初值的选择变得非常重要，常用的办法是选取几个不同的初值进行迭代，然后对得到的各个初值加以比较，从中选择最好的。</p>
<hr />
<h2>EM算法在高斯混合模型学习中的应用</h2>
<p>EM算法的一个重要应用是高斯混合模型的参数估计。</p>
<h3>高斯混合模型</h3>
<p>高斯混合模型是指具有如下形式的概率分布模型：
</p>
<div class="math">$$P(y|\theta)=\sum_{k=1}^{K}\alpha_k\phi(y|\theta_k)$$</div>
<p>
其中<span class="math">\(\alpha_k \geq 0\)</span>是系数（<span class="math">\(\sum_{k=1}^{K}\alpha_k = 1\)</span>）；<span class="math">\(\phi(y|\theta_k)\)</span>是高斯分布密度，<span class="math">\(\phi(y|\theta_k)=(\mu_k, \sigma_k^2)\)</span>
</p>
<div class="math">$$\phi(y|\theta_k)=\frac{1}{\sqrt{2\pi}\sigma_k}exp(-\frac{(y-\mu_k)^2}{2\sigma_k^2})$$</div>
<p>
称为第k个模型。</p>
<h3>高斯混合模型参数估计的EM算法</h3>
<p>我们用EM算法估计高斯混合模型的参数<span class="math">\(\theta=(\alpha_1,\alpha_2,...,\alpha_k;\theta_1,\theta_2,...,\theta_k)\)</span>。</p>
<p><strong>（1）明确隐变量，写出完全数据的对数似然函数</strong></p>
<p>第k个模型<span class="math">\(\phi(y|\theta_k)\)</span>生成的观测数据<span class="math">\(y_j\)</span>是已知的；但是观测数据来自于哪个模型是未知的，定义隐变量<span class="math">\(\gamma_{jk}\)</span>：
</p>
<div class="math">$$\gamma_{jk}=\left\{\begin{matrix}
1, &amp; 第j个观测来自第k个分模型\\ 
0, &amp; 否则
\end{matrix}\right.$$</div>
<p>
这样完全数据就是：
</p>
<div class="math">$$(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}), j=1,2,...,N$$</div>
<p>
于是，可以写出完全数据的似然函数：
</p>
<div class="math">$$P(y,\gamma|\theta)=\prod_{j=1}^{N}P(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)=...=\prod_{k=1}^{K}\alpha_k^{n_k}\prod_{j=1}^{N}[\frac{1}{\sqrt{2\pi}\sigma_k}exp(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]^{\gamma_{jk}}$$</div>
<p>
其中，<span class="math">\(n_k=\sum_{j=1}^{N}\gamma_{jk}\)</span>。</p>
<p>那么，完全数据的对数似然函数就为：
</p>
<div class="math">$$logP(y,\gamma|\theta)=\sum_{k=1}^{K}n_klog\alpha_k+\sum_{j=1}^{N}\gamma_{jk}[log\frac{1}{\sqrt{2\pi}\sigma_k}-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]$$</div>
<p>（2）EM算法的E步：确定Q函数
</p>
<div class="math">$$Q(\theta, \theta^{(i)})=E[logP(y,\gamma|\theta)|y,\theta^{(i)}]$$</div>
<p>（3）确定EM算法的M步</p>
<p>求使<span class="math">\(Q(\theta, \theta^{(i)})\)</span>极大化的<span class="math">\(\theta\)</span>，确定第i+1次迭代的参数估计值<span class="math">\(\theta^{(i+1)}\)</span></p>
<p>（4）重复直到收敛</p>
<hr />
<h2>EM算法的推广</h2>
<p>EM算法还可以解释<strong>为F函数的极大-极大算法</strong>，基于这个解释有若干变形与推广，如<strong>广义期望极大（GEM）算法</strong>。</p>
<h3>F函数的极大-极大算法</h3>
<p>假设隐变量数据Z的概率分布为<span class="math">\(\widetilde{P}(Z)\)</span>，定义分布<span class="math">\(\widetilde{P}\)</span>与参数<span class="math">\(\theta\)</span>的函数<span class="math">\(F(\widetilde{P}, \theta)\)</span>：
</p>
<div class="math">$$F(\widetilde{P}, \theta)=E_{\widetilde{P}}[logP(Y,Z|\theta)]+H(\widetilde{P})$$</div>
<p>
称为<strong>FF函数</strong>。式中<span class="math">\(H(\widetilde{P})\)</span>是分布<span class="math">\(\widetilde{P}(Z)\)</span>的熵。<span class="math">\(F(\widetilde{P}, \theta)\)</span>具有如下的性质：</p>
<p>（1）对于固定的<span class="math">\(\theta\)</span>，存在唯一的分布布<span class="math">\(\widetilde{P}(\theta)\)</span>极大化<span class="math">\(F(\widetilde{P}, \theta)\)</span>，这时<span class="math">\(\widetilde{P}(\theta)\)</span>由下式给出：
</p>
<div class="math">$$\widetilde{P}_\theta(Z)=P(Z|Y,\theta)$$</div>
<p>
并且<span class="math">\(\widetilde{P}(\theta)\)</span>随<span class="math">\(\theta\)</span>连续变化。</p>
<p>（2）若<span class="math">\(\widetilde{P}_\theta(Z) = P(Z|Y,\theta)\)</span>，则
</p>
<div class="math">$$F(\widetilde{P}, \theta)=logP(Y|\theta)$$</div>
<p>
于是，可以得到EM算法用F函数的极大-极大的解释。</p>
<p>（3）如果<span class="math">\(F(\widetilde{P}, \theta)\)</span>在<span class="math">\(\widetilde{P}^*\)</span>和<span class="math">\(\theta^*\)</span>有局部极大值，那么<span class="math">\(L(\theta)\)</span>也在<span class="math">\(\theta^*\)</span>有局部极大值。 类似的，如果<span class="math">\(F(\widetilde{P}, \theta)\)</span>在<span class="math">\(\widetilde{P}^*\)</span>和<span class="math">\(\theta^*\)</span>有全局极大值，那么<span class="math">\(L(\theta)\)</span>也在<span class="math">\(\theta^*\)</span>有全局极大值。</p>
<p>（4）<strong>EM算法的一次迭代可由F函数的极大-极大算法实现。</strong>
<span class="math">\(\theta^{(i)}\)</span>为第i次迭代参数的估计，<span class="math">\(\widetilde{P}^{(i)}\)</span>为第i次迭代函数<span class="math">\(\widetilde{P}\)</span>的估计。在第i+1次迭代的两步为：</p>
<ol>
<li>对固定的<span class="math">\(\theta^{(i)}\)</span>，求<span class="math">\(\widetilde{P}^{(i+1)}\)</span>使<span class="math">\(F(\widetilde{P}, \theta^{(i)})\)</span>极大化；</li>
<li>对固定的<span class="math">\(\widetilde{P}^{(i+1)}\)</span>，求<span class="math">\(\theta^{(i+1)}\)</span>使<span class="math">\(F(\widetilde{P}^{(i+1), \theta})\)</span>极大化；</li>
</ol>
<p>通过以上两步完成了EM算法的一次迭代。因此，EM算法与F函数的极大-极大算法得到的参数估计序列是一致的。</p>
<p>于是就有了EM算法的推广。</p>
<h3>GEM算法</h3>
<p><strong>GEM算法1：</strong></p>
<p>输入：观测数据，F函数</p>
<p>输出：模型参数</p>
<p>（1） 初始化参数<span class="math">\(\theta^{(0)}\)</span>，开始迭代</p>
<p>（2）第i+1次迭代，第1步：记<span class="math">\(\theta^{(i)}\)</span>为参数<span class="math">\(\theta\)</span>的估计值，<span class="math">\(\widetilde{P}^{(i)}\)</span>为<span class="math">\(\widetilde{P}\)</span>的估计。求<span class="math">\(\widetilde{P}^{(i+1)}\)</span>使<span class="math">\(F(\widetilde{P}, \theta^{(i)})\)</span>极大化</p>
<p>（3）第2步：求<span class="math">\(\theta^{(i+1)}\)</span>使<span class="math">\(F(\widetilde{P}^{(i+1), \theta})\)</span>极大化</p>
<p>（4）重复（2）和（3），直到收敛。</p>
<p><strong>GEM算法2：</strong></p>
<p>输入：观测数据，Q函数</p>
<p>输出：模型参数</p>
<p>（1）初始化参数<span class="math">\(\theta^{(0)}\)</span>，开始迭代</p>
<p>（2）第i+1次迭代，第1步：记<span class="math">\(\theta^{(i)}\)</span>为参数<span class="math">\(\theta\)</span>的估计值，计算
</p>
<div class="math">$$Q(\theta, \theta^{(i)})=E_Z[logP(Y,Z|\theta)|Y,\theta^{(i)}]=\sum_ZlogP(Y,Z|\theta)P(Z|y,\theta^{(i)})$$</div>
<p>（3）第2步：求<span class="math">\(\theta^{(i+1)}\)</span>使
</p>
<div class="math">$$Q(\theta^{(i+1)},\theta^{(i)}) \geq Q(\theta^{(i)}, \theta^{(i)})$$</div>
<p>（4）重复（2）和（3），直到收敛。</p>
<p>当参数<span class="math">\(\theta\)</span>的维数为d时，可以采用一种特殊的GEM法， 它将EM算法的M步分解为d次条件极大化， 每次只改变参数向量的一个分量，其余分量不改变。</p>
<p><strong>GEM算法3：</strong></p>
<p>输入：观测数据，Q函数</p>
<p>输出：模型参数</p>
<p>（1）初始化参数<span class="math">\(\theta^{(0)}\)</span>，开始迭代</p>
<p>（2）第i+1次迭代，第1步：记<span class="math">\(\theta^{(i)}=(\theta_1^{(i)},\theta_2^{(i)},...,\theta_d^{(i)})\)</span>为参数<span class="math">\(\theta\)</span>的估计值，计算
</p>
<div class="math">$$Q(\theta, \theta^{(i)})=E_Z[logP(Y,Z|\theta)|Y,\theta^{(i)}]=\sum_ZlogP(Y,Z|\theta)P(Z|y,\theta^{(i)})$$</div>
<p>（3）第2步：进行d次条件极大化：</p>
<p>首先，在<span class="math">\(\theta_2^{(i)},...,\theta_k^{(i)}\)</span>保持不变的条件下求使<span class="math">\(Q(\theta, \theta^{(i)})\)</span>达到极大的<span class="math">\(\theta_1^{(i+1)}\)</span></p>
<p>然后，在<span class="math">\(\theta_1^{(i)},\theta_3^{(i)},...,\theta_k^{(i)}\)</span>保持不变的条件下求使<span class="math">\(Q(\theta, \theta^{(i)})\)</span>达到极大的<span class="math">\(\theta_2^{(i+1)}\)</span></p>
<p>如此继续，经过d次条件极大化，得到求<span class="math">\(\theta^{(i+1)}\)</span>使
</p>
<div class="math">$$Q(\theta^{(i+1)},\theta^{(i)}) \geq Q(\theta^{(i)}, \theta^{(i)})$$</div>
<p>（4）重复（2）和（3），直到收敛。</p>
<hr />
<h2>Reference</h2>
<p><a href="http://book.douban.com/subject/10590856/">统计学习方法</a>第九章</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:Jesen">
<p><span class="math">\(log\sum_j\lambda_jy_j \geq \sum_j\lambda_jlogy_j\)</span>，其中<span class="math">\(\lambda_j \geq 0, \sum_j\lambda_j=1\)</span>&#160;<a class="footnote-backref" href="#fnref:Jesen" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div><!-- /.entry-content -->
            <div class="comments">
              <h3>Comments</h3>
              <div id="disqus_thread"></div>
              <script type="text/javascript">
                var disqus_identifier = "emsuan-fa.html";
                (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'http://wengwt.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
              </script>
            </div>


        </div><!-- /.eleven.columns -->

<div class="three columns">

<!--
<h4>Pages</h4>

 <ul>
      <li><a href="/categories.html">分类</a></li>
      <li><a href="/tags.html">标签</a></li>
      <li><a href="/archives.html">归档</a></li>
      <li><a href="/pages/about-me.html">关于我</a></li>
  </ul>
-->

<h4>分类</h4>
<ul>
		<li><a href="http://www.wengweitao.com/category/bian-cheng-yu-yan.html">编程语言</a></li>
		<li><a href="http://www.wengweitao.com/category/du-shu-bi-ji.html">读书笔记</a></li>
		<li><a href="http://www.wengweitao.com/category/gong-ju.html">工具</a></li>
		<li><a href="http://www.wengweitao.com/category/ji-qi-xue-xi.html">机器学习</a></li>
		<li><a href="http://www.wengweitao.com/category/python.html">Python</a></li>
		<li><a href="http://www.wengweitao.com/category/sheng-huo.html">生活</a></li>
		<li><a href="http://www.wengweitao.com/category/suan-fa-yu-shu-ju-jie-gou.html">算法与数据结构</a></li>
</ul>

<!--
<h4>标签</h4>
<ul class="tagcloud">
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/go.html">Go</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/wan.html">玩</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/du-shu-bi-ji.html">读书笔记</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/suan-fa-fen-xi.html">算法分析</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/tmux.html">tmux</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/jiao-cheng-linux.html">教程、Linux</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/python.html">Python</a></li>
        <li class="tag-3"><a href="http://www.wengweitao.com/tag/ji-ben-gai-nian.html">基本概念</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/ce-shi.html">测试</a></li>
        <li class="tag-2"><a href="http://www.wengweitao.com/tag/jiao-cheng.html">教程</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/ji-chu-gai-nian.html">基础概念</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/er-cha-shu.html">二叉树</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/pai-xu-suan-fa-ji-chu-zong-jie.html">排序 算法 基础 总结</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/pai-xu-suan-fa-ji-chu.html">排序 算法 基础</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/xiao-yuan.html">校园</a></li>
        <li class="tag-2"><a href="http://www.wengweitao.com/tag/mian-shi-ti.html">面试题</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/gong-ju.html">工具</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/vim.html">Vim</a></li>
</ul>
-->


<nav class="widget">
  <h4>社交</h4>
  <ul>
    <li><a href="http://weibo.com/u/2678027854">新浪微博</a></li>
    <li><a href="http://www.douban.com/people/wengwt/">豆瓣</a></li>
    <li><a href="http://www.zhihu.com/people/vita-49">知乎</a></li>
    <li><a href="https://github.com/nurnoch">Github</a></li>
    <li><a href="https://www.v2ex.com/member/wwttc">V2EX</a></li>
  </ul>
</nav>

<nav class="widget">
  <h4>友情链接</h4>
  <ul>
    <li><a href="http://netlab.pkusz.edu.cn/">互联网信息工程研发中心</a></li>
    <li><a href="http://www.houcj.net/">houcj's blog</a></li>
    <li><a href="http://www.rudy-yuan.net/">rundy-yuan's blog</a></li>
    <li><a href="http://zwyang.me/blog/">zwyanswer's blog</a></li>
  </ul>
</nav>


</div> </div><!-- /.row -->


</section>

       </div><!-- /.row -->
    </div><!-- /.container -->


       <div class="container.nopad bg">

    
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by  <a href="http://getpelican.com/">Pelican</a> and Theme by Gum © 2015 wwt
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">





              </ul>
            </div>
          </div>
        </footer>

    </div>


<script type="text/javascript">
    var disqus_shortname = 'wengwt';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
  <script src="http://www.wengweitao.com/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/libs/gumby.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/plugins.js"></script>
</body>
</html>