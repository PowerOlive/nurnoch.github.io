<!DOCTYPE html>
<html lang="zh">
<head>

        <title>wwt's blog</title>
        <meta charset="utf-8" />
        <link href="http://www.wengweitao.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="wwt's blog Full Atom Feed" />
        <link href="http://www.wengweitao.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="wwt's blog Full RSS Feed" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">
        <meta name="google-site-verification" content="pEViDEEJCicDD__DfnOAQ7xKtjtxJhVDoGDAOahOWy0" />

        <meta name="sogou_site_verification" content="ia8yXdZS0p"/>

        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/gumby.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/style.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/pygment.css" />


        <script src="http://www.wengweitao.com/theme/js/libs/modernizr-2.6.2.min.js"></script>




</head>

<body id="index" class="home">


    <div class="container">

        <div class="row">

          <header id="banner" class="body">
                  <h1><a href="http://www.wengweitao.com/">wwt's blog <strong></strong></a></h1>
          </header><!-- /#banner -->

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>
             
              <ul class="columns">
                <li><a href="http://www.wengweitao.com/">首页</a></li>

                <li><a href="/categories.html">分类</a></li>
                <li><a href="/tags.html">标签</a></li>
                <li><a href="/archives.html">归档</a></li>
                <li><a href="/pages/about-me.html">关于我</a></li>

              </ul>
            </div>

<section id="content">



   <div class="row">


        <div class="eleven columns">
                 <ol id="post-list">
                        <li><article class="hentry">
<<<<<<< HEAD
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/po-su-bei-xie-si-fa.html" rel="bookmark" title="Permalink to 朴素贝叶斯法">朴素贝叶斯法</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-28T14:06:00+08:00"> 一 28 七月 2014 </abbr>
=======
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-fei-xian-xing-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——非线性支持向量机">支持向量机——非线性支持向量机</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-08-04T19:39:00+08:00"> 一 04 八月 2014 </abbr>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a
                                    <address class="vcard author">By 
                                    <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
                                    </address>
                                </footer><!-- /.post-info -->
                                <div class="entry-content"> <blockquote>
<<<<<<< HEAD
<p>朴素贝叶斯法（naive Bayes）是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，利用特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。</p>
</blockquote>
<h2>朴素贝叶斯法的学习与分类</h2>
<h3>基本方法</h3>
<p>朴素贝叶斯法通过训练数据集学习联合概率分布P(X,Y).x为输入特征向量，y为输出的类标记。
先求先验概率
</p>
<div class="math">$$P(Y=c_k), k = 1,2,...,K$$</div>
<p>
然后求条件概率分布
</p>
<div class="math">$$P(X=x|Y=c_k)$$</div>
<p>
于是学习到联合概率分布P(X,Y)。</p>
<p>条件概率分布<span class="math">\(P(X=x|Y=c_k)\)</span>有指级数量的次数，其估计实际是不可行的。假设<span class="math">\(x^{(j)}\)</span>的可能有<span class="math">\(S_j\)</span>个，j=1 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/po-su-bei-xie-si-fa.html" rel="bookmark" title="Permalink to 朴素贝叶斯法">Read more <i class="icon-arrow-right"></i></a></div>
=======
<p>如果分类问题是非线性的，那么就要用到非线性支持向量机。非线性支持向量机主要特点就是利用核技巧。</p>
</blockquote>
<h2>核技巧</h2>
<h3>非线性分类问题</h3>
<p>利用非线性模型才能很好地进行分类的问题，就是非线性分类问题。如果能用<span class="math">\(R^n\)</span>中的一个超平面将正负例正确分开，则称这个问题为非线性可分问题。如下的例子，无法用直线（线性模型）将正负实例正确分开，但可以用一条椭圆（非线性模型）将它们正确分开。</p>
<p><img alt="非线性可分例子" src="./imgs/nolinear.png" /></p>
<p>通常进行一个非线性变换，将非线性问题变换为线性问题，通过解变换后的线性问题的方法求解原来的非线性问题。例如，上图中将椭圆变换为右图中的直线，将非线性分类问题变换为线性分类问题。</p>
<p>核技巧应用到支持向量机，其基本思想就是通过一个非线性变换将输入空间（欧氏空间<span class="math">\(R^n\)</span>或离散集合）对应于一个特征空间（希尔伯特空间<sup id="fnref:Hilbert"><a class="footnote-ref" href="#fn:Hilbert" rel="footnote">1</a></sup>H），使得在输入空间中的超平面模型对应于特征空间中的超平面模型（支持向量机）。这样，分类问题的学习任务通过在特征空间中求解线性支持向量机就可以完成。</p>
<h3>核函数的定义</h3>
<p>设<span class="math">\(\chi\)</span>是输入空间（欧氏空间<span class="math">\(R^n\)</span>的子集或离散集合），<span class="math">\(H\)</span>为特征空间（希尔伯特空间 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-fei-xian-xing-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——非线性支持向量机">Read more <i class="icon-arrow-right"></i></a></div>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a



                                <div class="row tag-row">
                                        <span>Tagged as : </span>
                                            <a class="danger label" href="http://www.wengweitao.com/tag/du-shu-bi-ji.html">读书笔记</a>
                                </div>



                        </article></li>
                        <li><article class="hentry">
<<<<<<< HEAD
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/kjin-lin-fa.html" rel="bookmark" title="Permalink to k近邻法">k近邻法</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-27T16:18:00+08:00"> 日 27 七月 2014 </abbr>
=======
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-xian-xing-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——线性支持向量机">支持向量机——线性支持向量机</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-08-03T14:54:00+08:00"> 日 03 八月 2014 </abbr>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a
                                    <address class="vcard author">By 
                                    <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
                                    </address>
                                </footer><!-- /.post-info -->
                                <div class="entry-content"> <blockquote>
<<<<<<< HEAD
<p>k近邻法（k-nearest neighbor, k-NN）是一种基于分类与回归的方法。分类时，对新的待分类的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显示的学习过程。k值的选择、距离度量及分类决策规则是k近邻法的3个基本要素。</p>
</blockquote>
<h2>k近邻算法</h2>
<p>k近邻算法简单、直观：对新的待分类的实例，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。</p>
<h2>k近邻模型</h2>
<p>k近邻法的使用的模型实际上对应于对特征空间的划分。模型由三个要素——距离度量、k值的选择和分类决策规则决定。</p>
<h3>模型</h3>
<p>当训练集、距离度量、k值以及分类决策规程确定后，对于任何一个新的输入实例，它所属的类唯一确定。k近邻法的模型对应特征空间的一个划分，将特征空间划分为一些子空间，确定子空间里的每一个点所属的类。</p>
<p>在特征空间中，对每个训练实例点<span class="math">\(x_i\)</span>，距离该点比其他点更近的所有点组成一个区域，叫做单元（cell）。最近邻将实例<span class="math">\(x_i\)</span>的类作为类<span class="math">\(y_i\)</span>作为其单元中所有点的类标记（class label）。</p>
<h3>距离度量</h3>
<p>特征空间中两个实例点的距离是两个实例点相似程度的反映。</p>
<p>设特征空间是n维实数向量空间，对于 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/kjin-lin-fa.html" rel="bookmark" title="Permalink to k近邻法">Read more <i class="icon-arrow-right"></i></a></div>
=======
<p>对于理想情况下线性可分的问题，可以使用上文介绍的线性可分支持向量机（硬间隔最大化）完美解决。但是，实际情况中，训练数据往往是线性不可分的，即在样本中存在噪声或特异点。此时，可以使用本文中介绍的更一般的学习算法——线性支持向量机（软间隔最大化）。</p>
</blockquote>
<h2>线性支持向量机</h2>
<p>怎样才能把<a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-xian-xing-ke-fen-zhi-chi-xiang-liang-ji.html">上文中介绍的线性可分支持向量机</a>扩展到线性不可分的数据集中呢？这就需要改变硬间隔最大化，使其成为软间隔最大化。</p>
<p>通常情况下，数据集中存在一些特异点（outlier），将这些特异点去除后，剩下大部分样本点组成的集合是线性可分的。那些线性不可分的样本点<span class="math">\((x_i, y_i)\)</span>意味着不能满足函数间隔大于等于1的约束条件（即<span class="math">\(y_i(w.x_i + b)-1 \geq 0\)</span>）。为了解决这个问题，可以为每个样本点引入一个松弛变量<span class="math">\(\xi_i \geq 0\)</span>，使函数间隔加上松弛变量后大于等于1.同时对每个松弛变量<span class="math">\(\xi_i\)</span>，支付一个代价<span class="math">\(\xi_i\)</span>。这样线性不可分的线性支持向量机的学习问题变成如下的凸二次规划问题：
</p>
<div class="math">$$min_{w,b,\xi ...</div> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-xian-xing-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——线性支持向量机">Read more <i class="icon-arrow-right"></i></a></div>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a



                                <div class="row tag-row">
                                        <span>Tagged as : </span>
                                            <a class="danger label" href="http://www.wengweitao.com/tag/du-shu-bi-ji.html">读书笔记</a>
                                </div>



                        </article></li>
                        <li><article class="hentry">
<<<<<<< HEAD
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/gan-zhi-ji.html" rel="bookmark" title="Permalink to 感知机">感知机</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-26T20:12:00+08:00"> 六 26 七月 2014 </abbr>
=======
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-xian-xing-ke-fen-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——线性可分支持向量机">支持向量机——线性可分支持向量机</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-08-02T20:32:00+08:00"> 六 02 八月 2014 </abbr>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a
                                    <address class="vcard author">By 
                                    <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
                                    </address>
                                </footer><!-- /.post-info -->
                                <div class="entry-content"> <blockquote>
<<<<<<< HEAD
<p>感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取+1和-1二值。感知机对应于输入空间中将实例划分为正负两类的分离超平面，属于判别模型。感知机学习旨在求出将训练数据进行线性划分的分离超平面，为此导入了基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。感知机学习算法具有简单而易于实现的优点，分为原始形式和对偶形式。感知机是神经网络与支持向量机的基础。</p>
</blockquote>
<h2>感知机模型</h2>
<p>由输入空间到输出空间的如下函数：
</p>
<div class="math">$$f(x)=sign(w.x+b)$$</div>
<p>
称为<strong>感知机</strong>。其中w和b称为感知机模型参数，<strong>w叫做权值</strong>（weight）或权值向量，b叫做偏置（bias）。感知机（perceptron）是<strong>二类分类的线性分类模型</strong>，属于判别模型。</p>
<p><strong>感知机的几何解释</strong>：线性方程
</p>
<div class="math">$$w.x+b=0$$</div>
<p>
对应于特征空间<span class="math">\(R^n\)</span>中的一个超平面S，其中w是超平面的法向量，b是超平面的截距。这个超平面将特征空间划分为两个部分 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/gan-zhi-ji.html" rel="bookmark" title="Permalink to 感知机">Read more <i class="icon-arrow-right"></i></a></div>
=======
<p>支持向量机（support vector machine， SVM）是一种二类分类模型。它的基本模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使之有别与感知机。支持向量机还包括核技巧，这使它成为实质上的非线性分类器。SVM的学习策略是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的学习算法是求解凸二次规划的最优算法。SVM学习方法包含构建由简至烦的模型：
- 线性可分支持向量机：当训练数据线性可分时，通过硬间隔最大化（hard margin maximization），学习一个线性分类器
- 线性支持向量机：当训练数据近似线性可分时，通过软间隔最大化（soft margin maximization），学习一个线性分类器，也称为软间隔支持向量机
- 非线性支持向量机：当训练数据线性不可分时，通过使用核技巧（kernel trick）即软间隔最大化，学习非线性支持向量机。
核函数（kernel function）表示将输入从输入空间映射到特征空间得到的特征向量之间的内积。通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。这样的方法称为核技巧。核方法是比支持向量机更为一般的机器学习方法。</p>
</blockquote>
<h2>线性可分支持向量机与硬间隔最大化</h2>
<h3>线性可分支持向量机</h3>
<p>支持向量机中，输入都由输入空间转换到特征空间将输入映射为特征向量，支持向量机的学习是在特征空间中进行的 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/zhi-chi-xiang-liang-ji-xian-xing-ke-fen-zhi-chi-xiang-liang-ji.html" rel="bookmark" title="Permalink to 支持向量机——线性可分支持向量机">Read more <i class="icon-arrow-right"></i></a></div>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a



                                <div class="row tag-row">
                                        <span>Tagged as : </span>
                                            <a class="danger label" href="http://www.wengweitao.com/tag/du-shu-bi-ji.html">读书笔记</a>
                                </div>



                        </article></li>
                        <li><article class="hentry">
<<<<<<< HEAD
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/ti-du-xia-jiang-fa.html" rel="bookmark" title="Permalink to 梯度下降法">梯度下降法</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-26T16:18:00+08:00"> 六 26 七月 2014 </abbr>
=======
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/luo-ji-si-di-hui-gui-yu-zui-da-shang-mo-xing.html" rel="bookmark" title="Permalink to 逻辑斯谛回归与最大熵模型">逻辑斯谛回归与最大熵模型</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-08-01T09:53:00+08:00"> 五 01 八月 2014 </abbr>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a
                                    <address class="vcard author">By 
                                    <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
                                    </address>
                                </footer><!-- /.post-info -->
<<<<<<< HEAD
                                <div class="entry-content"> <p><strong>梯度下降法（Gradient Descent）</strong>是一种常见的最优化算法，用于求解函数的最大值或者最小值。</p>
<h2>梯度的概念</h2>
<p>一个函数<span class="math">\(J(\theta)\)</span>对它的一个变量<span class="math">\(\theta\)</span>的梯度定义为：
</p>
<div class="math">$$\frac{\partial J(\theta))}{\partial \theta} = \lim_{\delta \theta\rightarrow 0}\frac{J(\theta + \delta \theta)-J(\theta ))}{\delta \theta}$$</div>
<p>
某一点上的梯度指向标量场增长最快的方向，梯度的长度就是最大的变化率。</p>
<h2>梯度下降</h2>
<p>在高数中，我们求解一个函数的最小值时，最常用的方法就是求出它的导数为0的那个点，进而判断这个点是否能够取最小值。但是，在实际很多情况，我们很难求解出使函数的导数为0的方程，这个时候就可以使用梯度下降。我们知道对于一个函数沿着梯度的那个方向是下降是最快的。例如为了选取一个<span class="math">\(\theta\)</span>使<span class="math">\(J(\theta)\)</span>最小 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/ti-du-xia-jiang-fa.html" rel="bookmark" title="Permalink to 梯度下降法">Read more <i class="icon-arrow-right"></i></a></div>
=======
                                <div class="entry-content"> <blockquote>
<p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类方法，可以用于二类分类也可以用于多类分类。最大熵模型由最大熵原理推导出来，最大熵原理是概率模型学习或估计的一个准则，最大熵原理认为在所有可能的概率模型的集合中，熵最大的模型是最好的模型，最大熵模型也可以用于二类分类和多类分类。逻辑斯谛回归模型与最大熵模型都属于对数线性模型<sup id="fnref:log"><a class="footnote-ref" href="#fn:log" rel="footnote">1</a></sup></p>
</blockquote>
<h2>逻辑斯谛回归模型</h2>
<h3>逻辑斯谛分布</h3>
<p>设X是连续随机变量，X服从逻辑斯谛分布是指X具有如下分布函数和密度函数：
</p>
<div class="math">$$F(X)=P(X \leq x)=\frac{1}{1+e^{-(x-u)/\gamma}}$$</div>
<div class="math">$$f(x)=F'(x)=\frac{e^{-(x-u)/\gamma}}{\gamma(1+e^{-(x-u)/\gamma})^2}$$</div>
<p>
其中<span class="math">\(\mu\)</span>为位置参数，<span class="math">\(\gamma &gt; 0\)</span>为形状参数。
<strong>分布函数的图形是一条S形曲线</strong>（sigmoid ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/luo-ji-si-di-hui-gui-yu-zui-da-shang-mo-xing.html" rel="bookmark" title="Permalink to 逻辑斯谛回归与最大熵模型">Read more <i class="icon-arrow-right"></i></a></div>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a



                                <div class="row tag-row">
                                        <span>Tagged as : </span>
                                            <a class="danger label" href="http://www.wengweitao.com/tag/ji-ben-gai-nian.html">基本概念</a>
                                </div>



                        </article></li>
                        <li><article class="hentry">
<<<<<<< HEAD
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/tong-ji-xue-xi-fang-fa-gai-lun.html" rel="bookmark" title="Permalink to 统计学习方法概论">统计学习方法概论</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-25T20:12:00+08:00"> 五 25 七月 2014 </abbr>
=======
                                <header> <h2 class="entry-title"><a href="http://www.wengweitao.com/niu-dun-fa.html" rel="bookmark" title="Permalink to 牛顿法">牛顿法</a></h2> </header>
                                <footer class="post-info">
                                    <abbr class="published" title="2014-07-30T20:12:00+08:00"> 三 30 七月 2014 </abbr>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a
                                    <address class="vcard author">By 
                                    <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
                                    </address>
                                </footer><!-- /.post-info -->
                                <div class="entry-content"> <blockquote>
<<<<<<< HEAD
<p>本文主要介绍统计学习方法的一些基本概念。首先叙述统计学习的定义、研究对象与方法；然后叙述什么是监督学习；接着提出统计学习方法的三要素：模型、测量和算法；然后又介绍了模型选择的方法，包括：正则化与交叉验证；也介绍了学习方法的泛化能力；接着介绍了监督学习中的两种模型：生成模型和判别模型；最后介绍了监督学习方法的应用：分类问题、标注问题与回归问题。</p>
</blockquote>
<h2>统计学习</h2>
<h3>统计学习的特点</h3>
<p><strong>统计学习（statistical learning）</strong>是关于计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的一门学科。</p>
<ul>
<li>研究对象：数据</li>
<li>目的：对数据进行预测和分析</li>
<li>以方法为中心，统计学习方法构建模型并运用模型进行预测与分析</li>
<li>是概率论、统计学等多个学科的交叉</li>
</ul>
<h3>统计学习的对象</h3>
<p>统计学习的对象是数据（data），并且假设同类数据具有一定的统计规律性，这是统计学习的前提。只有具有一定的统计规律性才能使用概率论的方法进行描述。</p>
<h3>统计学习的目的</h3>
<p>考虑学习什么样的模型和如何学习模型，以使模型能够对数据进行准确的预测与分析，同时也要尽可能考虑学习的效率。</p>
<h3>统计学习的方法</h3>
<p>统计学习由：</p>
<ul>
<li>监督学习（supervised learning）</li>
<li>非监督学习（unsupervised learning）</li>
<li>半监督学习（semi-supervised ...</li></ul> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/tong-ji-xue-xi-fang-fa-gai-lun.html" rel="bookmark" title="Permalink to 统计学习方法概论">Read more <i class="icon-arrow-right"></i></a></div>
=======
<p>牛顿法是近似求解方程的方法，方法是使用函数的泰勒级数的前面几项来寻找方程的根。在统计学习中，牛顿法（Newton method）和拟牛顿法（quasi Newton method）也是<strong>求解无约束最优化问题</strong>的常用方法。有<strong>收敛速度快</strong>的优点。牛顿法是<strong>迭代方法</strong>，每一步需要求解目标函数的海森矩阵（Hessian matrix）的逆矩阵，计算比较复杂。拟牛顿法通过正定矩阵近似海赛矩阵的逆矩阵或海赛矩阵，简化了这一过程。</p>
</blockquote>
<h2>牛顿法</h2>
<h3>目标</h3>
<p>考虑无约束最优化问题
</p>
<div class="math">$$minf(x)$$</div>
<p>其中<span class="math">\(x^*\)</span>为目标函数的极小点。求出f(x)的极小点 <span class="math">\(x^*\)</span></p>
<p>首先，我们先了解下泰勒级数与海森矩阵。</p>
<h3>基本概念</h3>
<h4>泰勒级数</h4>
<p>若函数f（x）在点的某一临域内具有直到（n+1）阶导数，则在该邻域内f（x）的n阶泰勒公式为 ...</p> </div><!-- /.entry-content -->

                                <div class="medium primary btn"><a href="http://www.wengweitao.com/niu-dun-fa.html" rel="bookmark" title="Permalink to 牛顿法">Read more <i class="icon-arrow-right"></i></a></div>
>>>>>>> 700a254393e115d0e8df2dc309357b2ba17b3d4a



                                <div class="row tag-row">
                                        <span>Tagged as : </span>
                                            <a class="danger label" href="http://www.wengweitao.com/tag/ji-ben-gai-nian.html">基本概念</a>
                                </div>



                        </article></li>
                </ol><!-- /#posts-list -->

        </div><!-- /.eleven.columns -->
        
<div class="three columns">

<!--
<h4>Pages</h4>

 <ul>
      <li><a href="/categories.html">分类</a></li>
      <li><a href="/tags.html">标签</a></li>
      <li><a href="/archives.html">归档</a></li>
      <li><a href="/pages/about-me.html">关于我</a></li>
  </ul>
-->

<aside id="sidebar"><!--Google站内搜索开始-->
        <div class="search">
                <!--<h2>站内搜索</h2>-->
                <form method=get action="http://www.google.com/search">
                <input type=text name=q>
                <input type=submit name=btnG value="搜索">
                <input type=hidden name=ie value=UTF-8>
                <input type=hidden name=oe value=UTF-8>
                <input type=hidden name=hl value=zh-CN>
                <input type=hidden name=domains value="http://www.wengweitao.com">
                <input type=hidden name=sitesearch value="http://www.wengweitao.com">
                </form>
        </div>
<!--Google站内搜索结束-->

<h4>分类</h4>
<ul>
		<li><a href="http://www.wengweitao.com/category/bian-cheng-yu-yan.html">编程语言</a></li>
		<li><a href="http://www.wengweitao.com/category/csji-chu.html">CS基础</a></li>
		<li><a href="http://www.wengweitao.com/category/du-shu-bi-ji.html">读书笔记</a></li>
		<li><a href="http://www.wengweitao.com/category/gong-ju.html">工具</a></li>
		<li><a href="http://www.wengweitao.com/category/ji-qi-xue-xi.html">机器学习</a></li>
		<li><a href="http://www.wengweitao.com/category/ji-zhu.html">技术</a></li>
		<li><a href="http://www.wengweitao.com/category/python.html">Python</a></li>
		<li><a href="http://www.wengweitao.com/category/sheng-huo.html">生活</a></li>
		<li><a href="http://www.wengweitao.com/category/suan-fa-yu-shu-ju-jie-gou.html">算法与数据结构</a></li>
</ul>

<!--
<h4>标签</h4>
<ul class="tagcloud">
</ul>
-->


<nav class="widget">
  <h4>社交</h4>
  <ul>
    <li><a href="http://weibo.com/u/2678027854">新浪微博</a></li>
    <li><a href="http://www.douban.com/people/wengwt/">豆瓣</a></li>
    <li><a href="http://www.zhihu.com/people/vita-49">知乎</a></li>
    <li><a href="https://github.com/nurnoch">GitHub</a></li>
    <li><a href="https://www.v2ex.com/member/wwttc">V2EX</a></li>
    <li><a href="https://www.instagram.com/wwt836/">instagram</a></li>
  </ul>
</nav>

<nav class="widget">
  <h4>友情链接</h4>
  <ul>
    <li><a href="http://www.rudy-yuan.net/">rundy-yuan's blog</a></li>
    <li><a href="http://www.houcj.net/">houcj's blog</a></li>
    <li><a href="http://zwyang.me/blog/">zwyanswer's blog</a></li>
  </ul>
</nav>


</div> </div><!-- /.row -->

<p class="paginator">
            <a href="http://www.wengweitao.com/index11.html"><i class="icon-arrow-left"></i></a>
    Page 12 / 14
        <a href="http://www.wengweitao.com/index13.html"><i class="icon-arrow-right"></i></a>
</p>
</section><!-- /#content -->

       </div><!-- /.row -->
    </div><!-- /.container -->


       <div class="container.nopad bg">

    
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by  <a href="http://getpelican.com/">Pelican</a> and Theme by Gum © 2015 wwt       
                       <!-- cnzz -->
                    <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1255354158'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1255354158%26show%3Dpic2' type='text/javascript'%3E%3C/script%3E"));</script>  
                    </address>
                   
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">





              </ul>
            </div>
          </div>
        </footer>

    </div>



<script type="text/javascript">
    var disqus_shortname = 'wengwt';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
  <script src="http://www.wengweitao.com/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/libs/gumby.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/plugins.js"></script>
</body>
</html>