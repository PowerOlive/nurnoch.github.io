<!DOCTYPE html>
<html lang="zh">
<head>

        <title>逻辑斯谛回归与最大熵模型</title>
        <meta charset="utf-8" />
        <link href="http://www.wengweitao.com/feeds\all.atom.xml" type="application/atom+xml" rel="alternate" title="wwt's blog Full Atom Feed" />
        <link href="http://www.wengweitao.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="wwt's blog Full RSS Feed" />
        <link href="http://www.wengweitao.com/feeds/ji-qi-xue-xi.rss.xml" type="application/atom+xml" rel="alternate" title="wwt's blog Categories Atom Feed" />


        <!-- Mobile viewport optimized: j.mp/bplateviewport -->
        <meta name="viewport" content="width=device-width,initial-scale=1, maximum-scale=1">
        <meta name="google-site-verification" content="pEViDEEJCicDD__DfnOAQ7xKtjtxJhVDoGDAOahOWy0" />

        <meta name="sogou_site_verification" content="ia8yXdZS0p"/>
 

        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/gumby.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/style.css" />
        <link rel="stylesheet" type="text/css" href="http://www.wengweitao.com/theme/pygment.css" />

        <script src="http://www.wengweitao.com/theme/js/libs/modernizr-2.6.2.min.js"></script>




</head>

<body id="index" class="home">


    <div class="container">

        <div class="row">

          <header id="banner" class="body">
                  <h1><a href="http://www.wengweitao.com/">wwt's blog <strong></strong></a></h1>
          </header><!-- /#banner -->

            <div id="navigation" class="navbar row">
              <a href="#" gumby-trigger="#navigation &gt; ul" class="toggle"><i class="icon-menu"></i></a>
             
              <ul class="columns">
                <li><a href="http://www.wengweitao.com/">首页</a></li>

                <li><a href="/categories.html">分类</a></li>
                <li><a href="/tags.html">标签</a></li>
                <li><a href="/archives.html">归档</a></li>
                <li><a href="/pages/about-me.html">关于我</a></li>

              </ul>
            </div>

<section id="content" class="body">

   <div class="row">
        <div class="eleven columns">


            <header>
              <h2 class="entry-title">
                <a href="http://www.wengweitao.com/luo-ji-si-di-hui-gui-yu-zui-da-shang-mo-xing.html" rel="bookmark"
                   title="Permalink to 逻辑斯谛回归与最大熵模型">逻辑斯谛回归与最大熵模型</a></h2>
           
            </header>
            <footer class="post-info">
              <abbr class="published" title="2014-08-01T09:53:00">
                Fri 01 August 2014
              </abbr>
              <address class="vcard author">By 
                <a class="url fn" href="http://www.wengweitao.com/author/wwt.html"> wwt</a>
              </address>
            </footer><!-- /.post-info -->
            <div class="entry-content">
              <blockquote>
<p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类方法，可以用于二类分类也可以用于多类分类。最大熵模型由最大熵原理推导出来，最大熵原理是概率模型学习或估计的一个准则，最大熵原理认为在所有可能的概率模型的集合中，熵最大的模型是最好的模型，最大熵模型也可以用于二类分类和多类分类。逻辑斯谛回归模型与最大熵模型都属于对数线性模型<sup id="fnref:log"><a class="footnote-ref" href="#fn:log" rel="footnote">1</a></sup></p>
</blockquote>
<h2>逻辑斯谛回归模型</h2>
<h3>逻辑斯谛分布</h3>
<p>设X是连续随机变量，X服从逻辑斯谛分布是指X具有如下分布函数和密度函数：
</p>
<div class="math">$$F(X)=P(X \leq x)=\frac{1}{1+e^{-(x-u)/\gamma}}$$</div>
<div class="math">$$f(x)=F'(x)=\frac{e^{-(x-u)/\gamma}}{\gamma(1+e^{-(x-u)/\gamma})^2}$$</div>
<p>
其中<span class="math">\(\mu\)</span>为位置参数，<span class="math">\(\gamma &gt; 0\)</span>为形状参数。
<strong>分布函数的图形是一条S形曲线</strong>（sigmoid curve），是中心对称的，曲线在中心点附近增长的较快，在两端增长的较慢。<span class="math">\(\gamma\)</span>的值越小，曲线在中心附近增长的越快。</p>
<h3>逻辑斯谛回归模型</h3>
<p><strong>二项逻辑斯谛回归模型</strong>是如下的条件概率分布：
</p>
<div class="math">$$P(Y=1|x)=\frac{exp(w.x+b)}{1+exp(w.x+b)}$$</div>
<div class="math">$$P(Y=0|x)=\frac{1}{1+exp(w.x+b)}$$</div>
<p>
随机变量X取值为实数，输出Y是0或1，w称为权值向量，b称为偏置。二项逻辑斯谛回归模型是一种分类模型，由条件概率P(Y|X)表示，形式为参数化的逻辑斯谛分布。</p>
<p>有时为了方便，将权值向量和输入向量加以扩展，将偏置放入权值向量中，输入向量也增加一个值为1的分量，这时逻辑斯谛回归模型可以表示为：
</p>
<div class="math">$$P(Y=1|x)=\frac{exp(w.x)}{1+exp(w.x)}$$</div>
<div class="math">$$P(Y=0|x)=\frac{1}{1+exp(w.x)}$$</div>
<p>对逻辑斯谛回归而言，x输入分类为Y=1的对数几率<sup id="fnref:odds"><a class="footnote-ref" href="#fn:odds" rel="footnote">2</a></sup>或logit函数是：
</p>
<div class="math">$$log\frac{P(Y=1|X)}{P(Y=0|X)}=w.x$$</div>
<p>
也就是说再逻辑斯谛回归模型中，输出Y=1的对数几率是输入x的线性函数。或者<strong>说Y=1的对数几率是由输入x的线性函数<span class="math">\(w.x\)</span>表示的模型，即逻辑斯谛回归模型</strong>。
线性函数越接近正无穷，概率值就越接近1；越接近负无穷，概率值就越接近0.这样的模型就是逻辑斯谛回归模型。</p>
<p>而在使用线性回归进行二类分类的时候：
</p>
<div class="math">$$P(Y=1|x)= w_0 + w_1x_1 + ... + w_nx_n$$</div>
<p>
存在两个问题：</p>
<p>（1）等式两边的取值范围不同。左边为概率是[0, 1]，右边是无穷</p>
<p>（2）实际很多问题中，概率P和输入并非简单的线性关系，在x很小或很大的时候，可能对于P的影响很小，而x在某些值附近可能对P的影响很大。</p>
<p>逻辑斯谛回归模型对线性回归模型进行了修正，解决了以上的2个问题。</p>
<h3>模型参数估计</h3>
<p>我们通过监督学习的方法来估计模型参数。对于给定的训练数据集，可以运用极大似然法估计模型参数，从而得到逻辑斯谛回归模型。</p>
<p>假设
</p>
<div class="math">$$P(Y=1|X)=\pi(x)$$</div>
<div class="math">$$P(Y=0|X)=1 - \pi(x)$$</div>
<p>
似然函数可以表示为
</p>
<div class="math">$$\prod_{i=1}^{N}[\pi(x_i)]^{y_i}[1 - \pi(x_i)]^{1-y_i}$$</div>
<p>
对数似然函数表示为<span class="math">\(L(w)\)</span>，<strong>对<span class="math">\(L(w)\)</span>求最大值，得到w的估计值</strong>。得到了
w就可以学到逻辑斯谛回归模型。</p>
<p>这样问题就变成了以对数似然函数为目标的最优化问题。逻辑斯谛回归学习中常用的方法是梯度下降<sup id="fnref:gradient descent"><a class="footnote-ref" href="#fn:gradient descent" rel="footnote">3</a></sup>及拟牛顿法<sup id="fnref:newton method"><a class="footnote-ref" href="#fn:newton method" rel="footnote">4</a></sup>。</p>
<h3>多项逻辑斯谛回归</h3>
<p>上面介绍的是二类分类，也可以将逻辑斯谛回归模型推广到多类分类。假设离散型随机变量Y的取值集合是{1,2,...,K}，那么多项逻辑斯谛回归模型是
</p>
<div class="math">$$P(Y=k|x)=\frac{exp(w_k.x)}{1+\sum_{k=1}^{K-1}exp(w_k.x)}$$</div>
<div class="math">$$P(Y=K|x)=\frac{1}{1+\sum_{k=1}^{K-1}exp(w_k.x)}$$</div>
<hr />
<h2>最大熵模型</h2>
<h3>最大熵原理</h3>
<p>最大熵原理认为，学习概率模型时，在所有可能的概率模型中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合。最大熵原理认为选择的概率模型首先必须满足已有的事实，即约束条件。所以最大熵原理可以表示为：<strong>在满足约束条件的模型集合中选取熵最大的模型。</strong></p>
<p>在没有更多信息的情况下，可以按照满足约束条件下求等概率的方法估计概率分布（因为均匀分布，熵最大）。</p>
<h3>最大熵模型的定义</h3>
<p>将最大熵原理应用到分类就得到最大熵模型。</p>
<p>给定训练数据集可以确定联合分布P(X,Y)的经验分布和边缘分布P(X)的经验分布<span class="math">\(\widetilde{P}(X,Y)和\widetilde{P}(X)\)</span>。用特征函数f(x,y)描述输入x和输出y之间的某一个事实，定义为：
</p>
<div class="math">$$f(x,y)=\left\{\begin{matrix}
1,x与y满足某一事实\\ 
0,不满足某一事实
\end{matrix}\right.$$</div>
<p>特征函数f(x,y)<strong>关于经验分布<span class="math">\(\widetilde{P}(X,Y)\)</span>的期望值</strong>，用<span class="math">\(E_\widetilde{P}(f)\)</span>表示：
</p>
<div class="math">$$E_\widetilde{P}(f)=\sum_{x,y}\widetilde{P}(x,y)f(x,y)$$</div>
<p>特征函数f(x,y)<strong>关于模型P(Y|X)与经验分布<span class="math">\(\widetilde{P}(X)\)</span>的期望值</strong>，用<span class="math">\(E_{P}(f)\)</span>表示：
 </p>
<div class="math">$$E_p(f)=\sum_{x,y}\widetilde{P}(X)P(y|x)f(x,y)$$</div>
<p>如果模型可以获取训练数据中的信息，那么可以假设以上两个期望值相等：
 </p>
<div class="math">$$E_\widetilde{P}(f)=E_p(f)$$</div>
<p>
 或
 </p>
<div class="math">$$\sum_{x,y}\widetilde{P}(x,y)f(x,y)=\sum_{x,y}\widetilde{P}(X)P(y|x)f(x,y)$$</div>
<p>
以上两式作为<strong>模型学习的约束条件</strong>。假如有n个特征函数<span class="math">\(f_i(x,y)， i=1,2,...,n\)</span>那么就有<em>n个约束条件</em>。</p>
<h3>最大熵模型的学习</h3>
<p>最大熵模型的学习可以形式化为约束最优化问题。</p>
<p>给定训练数据集T已经特征函数<span class="math">\(f_i(x,y)， i=1,2,...,n\)</span>，最大熵模型的学习等价于约束最优化问题：
</p>
<div class="math">$$max_{P \in C} H(P)=-\sum_{x,y}\widetilde{P}(x)P(y|x)logP(y|x)$$</div>
<div class="math">$$s.t. E_\widetilde{P}(f)=E_p(f)， i=1,2,...,n　并且　\sum_yP(y|x)=1$$</div>
<p>
按照最优化问题的习惯，将求最大值问题改写为等价的求最小值问题：
</p>
<div class="math">$$min_{P \in C} -H(P)=\sum_{x,y}\widetilde{P}(x)P(y|x)logP(y|x)$$</div>
<div class="math">$$s.t. E_\widetilde{P}(f)-E_p(f)=0， i=1,2,...,n　并且　\sum_yP(y|x)=1$$</div>
<p>
求解以上最优化问题，所得出的解，就是最大熵模型学习的解。</p>
<p>这里，将约束最优化问题的原始问题转换为无约束最优化的对偶问题，通过求解对偶问题求解原始问题。</p>
<p>（1）引入拉格朗日乘子，定义拉格朗日函数<span class="math">\(L(P,w)\)</span>。</p>
<p>（2）首先求解<span class="math">\(L(P,w)\)</span>关于P的极小化问题，固定拉格朗日乘子<span class="math">\(w_0,w_1,...,w_n\)</span>，对P求偏导数</p>
<p>（3）另各偏导数等于0，解出各个P，得到<span class="math">\(min_PL(P,w)\)</span></p>
<p>（4）求解<span class="math">\(L(P_w,w)\)</span>关于w的极大化问题</p>
<p>（5）令<span class="math">\(L(P_w,w)\)</span>对w的各偏导数为0</p>
<p>（6）得到最大熵模型</p>
<p>可以求解得到：
</p>
<div class="math">$$P_w(y|x)=\frac{1}{Z_w(x)}exp(\sum_{i=1}^{n}w_if_i(x,y))$$</div>
<p>
其中
</p>
<div class="math">$$Z_w(x)=\sum_{y}exp(\sum_{i=1}^{n}w_if_i(x,y))$$</div>
<p>
<span class="math">\(Z_w(x)\)</span>称为<strong>规范化因子</strong>；<span class="math">\(f_i(x,y)\)</span>是特征函数；<span class="math">\(w_i\)</span>是特征的权值。有上式表示的模型<span class="math">\(P_w=P_w(y|x)\)</span>就是最大熵模型。最后，最大熵模型的学习归结为对偶函数的极大化。</p>
<h3>极大似然函数</h3>
<p>可以证明对偶函数的极大化等价于最大熵模型的极大似然估计。这样最大熵模型的学习问题就转化为具体求解对数似然函数极大化或对偶函数极大化问题。</p>
<p>最大熵模型与逻辑斯谛回归模型有类似的形式，它们又称为<strong>对数线性模型(log linear model)</strong>。模型学习就是在给定的训练数据条件下对模型进行极大似然估计或正则化的极大似然估计。</p>
<hr />
<h2>模型学习的最优化选择</h2>
<p>最大熵模型与逻辑斯谛回归模型学习归结为以似然函数为目标函数的最优化问题，通常通过迭代算法求解。这时的目标函数是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。牛顿法或拟牛顿法一般收敛速度更快。</p>
<h3>改进的迭代尺度法</h3>
<p><strong>改进的迭代尺度法（improved iterative scaling, IIS）</strong>是一种最大熵模型学习的最优化算法。IIS的想法是：假设最大熵模型的当前的参数向量是<span class="math">\(w\)</span>，我们希望找到一个新的参数向量<span class="math">\(w=w+\delta\)</span>，使得模型的对数似然函数值增大。如果能有一种参数向量的更新方法<span class="math">\(w \rightarrow w+\delta\)</span>，那么就可以重复使用这一方法，直到找到对数似然函数的最大值。</p>
<h3>拟牛顿法</h3>
<p>最大熵模型还可以使用牛顿法或拟牛顿法。</p>
<hr />
<h2>Reference</h2>
<p><a href="http://book.douban.com/subject/10590856/">统计学习方法</a>第六章</p>
<p>http://blog.csdn.net/lilyth_lilyth/article/details/10032993</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:log">
<p>对数线性模型是对线性模型的一个变形，使用原始数据的对数建模。&#160;<a class="footnote-backref" href="#fnref:log" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:odds">
<p>一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。&#160;<a class="footnote-backref" href="#fnref:odds" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:gradient descent">
<p>参考我之前的另一篇文章<a href="http://www.wengweitao.com/ti-du-xia-jiang-fa.html">梯度下降法</a> &#160;<a class="footnote-backref" href="#fnref:gradient descent" rev="footnote" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:newton method">
<p>参考我之前的另一篇文章<a href="http://www.wengweitao.com/niu-dun-fa.html">牛顿法</a>&#160;<a class="footnote-backref" href="#fnref:newton method" rev="footnote" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
</ol>
</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </div><!-- /.entry-content -->
            <div class="comments">
              <h3>Comments</h3>
              <div id="disqus_thread"></div>
              <script type="text/javascript">
                var disqus_identifier = "luo-ji-si-di-hui-gui-yu-zui-da-shang-mo-xing.html";
                (function() {
                var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                dsq.src = 'http://wengwt.disqus.com/embed.js';
                (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
              </script>
            </div>


        </div><!-- /.eleven.columns -->

<div class="three columns">

<!--
<h4>Pages</h4>

 <ul>
      <li><a href="/categories.html">分类</a></li>
      <li><a href="/tags.html">标签</a></li>
      <li><a href="/archives.html">归档</a></li>
      <li><a href="/pages/about-me.html">关于我</a></li>
  </ul>
-->

<aside id="sidebar"><!--Google站内搜索开始-->
        <div class="search">
                <!--<h2>站内搜索</h2>-->
                <form method=get action="http://www.google.com/search">
                <input type=text name=q>
                <input type=submit name=btnG value="搜索">
                <input type=hidden name=ie value=UTF-8>
                <input type=hidden name=oe value=UTF-8>
                <input type=hidden name=hl value=zh-CN>
                <input type=hidden name=domains value="http://www.wengweitao.com">
                <input type=hidden name=sitesearch value="http://www.wengweitao.com">
                </form>
        </div>
<!--Google站内搜索结束-->

<h4>分类</h4>
<ul>
		<li><a href="http://www.wengweitao.com/category/bian-cheng-yu-yan.html">编程语言</a></li>
		<li><a href="http://www.wengweitao.com/category/du-shu-bi-ji.html">读书笔记</a></li>
		<li><a href="http://www.wengweitao.com/category/gong-ju.html">工具</a></li>
		<li><a href="http://www.wengweitao.com/category/ji-qi-xue-xi.html">机器学习</a></li>
		<li><a href="http://www.wengweitao.com/category/python.html">Python</a></li>
		<li><a href="http://www.wengweitao.com/category/sheng-huo.html">生活</a></li>
		<li><a href="http://www.wengweitao.com/category/suan-fa-yu-shu-ju-jie-gou.html">算法与数据结构</a></li>
</ul>

<!--
<h4>标签</h4>
<ul class="tagcloud">
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/suan-fa-fen-xi.html">算法分析</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/python.html">Python</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/go.html">Go</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/du-shu-bi-ji.html">读书笔记</a></li>
        <li class="tag-3"><a href="http://www.wengweitao.com/tag/leetcode.html">leetcode</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/vim.html">Vim</a></li>
        <li class="tag-2"><a href="http://www.wengweitao.com/tag/jiao-cheng.html">教程</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/jiao-cheng-linux.html">教程、Linux</a></li>
        <li class="tag-3"><a href="http://www.wengweitao.com/tag/ji-ben-gai-nian.html">基本概念</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/er-cha-shu.html">二叉树</a></li>
        <li class="tag-2"><a href="http://www.wengweitao.com/tag/mian-shi-ti.html">面试题</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/ce-shi.html">测试</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/ji-chu-gai-nian.html">基础概念</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/pai-xu-suan-fa-ji-chu-zong-jie.html">排序 算法 基础 总结</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/gong-ju.html">工具</a></li>
        <li class="tag-1"><a href="http://www.wengweitao.com/tag/pai-xu-suan-fa-ji-chu.html">排序 算法 基础</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/tmux.html">tmux</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/wan.html">玩</a></li>
        <li class="tag-4"><a href="http://www.wengweitao.com/tag/xiao-yuan.html">校园</a></li>
</ul>
-->


<nav class="widget">
  <h4>社交</h4>
  <ul>
    <li><a href="http://weibo.com/u/2678027854">新浪微博</a></li>
    <li><a href="http://www.douban.com/people/wengwt/">豆瓣</a></li>
    <li><a href="http://www.zhihu.com/people/vita-49">知乎</a></li>
    <li><a href="https://github.com/nurnoch">Github</a></li>
    <li><a href="https://www.v2ex.com/member/wwttc">V2EX</a></li>
  </ul>
</nav>

<nav class="widget">
  <h4>友情链接</h4>
  <ul>
    <li><a href="http://netlab.pkusz.edu.cn/">互联网信息工程研发中心</a></li>
    <li><a href="http://www.houcj.net/">houcj's blog</a></li>
    <li><a href="http://www.rudy-yuan.net/">rundy-yuan's blog</a></li>
    <li><a href="http://zwyang.me/blog/">zwyanswer's blog</a></li>
  </ul>
</nav>


</div> </div><!-- /.row -->


</section>

       </div><!-- /.row -->
    </div><!-- /.container -->


       <div class="container.nopad bg">

    
        <footer id="credits" class="row">
          <div class="seven columns left-center">

                   <address id="about" class="vcard body">
                    Proudly powered by  <a href="http://getpelican.com/">Pelican</a> and Theme by Gum © 2015 wwt
                    </address>
          </div>


          <div class="seven columns">
            <div class="row">
              <ul class="socbtns">





              </ul>
            </div>
          </div>
        </footer>

    </div>


<script type="text/javascript">
    var disqus_shortname = 'wengwt';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
  <script src="http://www.wengweitao.com/theme/js/libs/jquery-1.9.1.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/libs/gumby.min.js"></script>
  <script src="http://www.wengweitao.com/theme/js/plugins.js"></script>
</body>
</html>